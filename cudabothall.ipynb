{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyN1suX1ZTCutFRx30sDqxoA"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","source":["!nvcc --version"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1SabQ_kA8XFl","executionInfo":{"status":"ok","timestamp":1684849194037,"user_tz":-330,"elapsed":1542,"user":{"displayName":"Neelam Khada","userId":"05506283173872221635"}},"outputId":"84c1d25f-4553-45bc-fc19-301878d0c9e6"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["nvcc: NVIDIA (R) Cuda compiler driver\n","Copyright (c) 2005-2022 NVIDIA Corporation\n","Built on Wed_Sep_21_10:33:58_PDT_2022\n","Cuda compilation tools, release 11.8, V11.8.89\n","Build cuda_11.8.r11.8/compiler.31833905_0\n"]}]},{"cell_type":"code","source":["!pip install git+https://github.com/andreinechaev/nvcc4jupyter.git\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DoVKkEkB8b-A","executionInfo":{"status":"ok","timestamp":1684849205365,"user_tz":-330,"elapsed":2642,"user":{"displayName":"Neelam Khada","userId":"05506283173872221635"}},"outputId":"1695d960-22ac-4225-de0c-45d14443670f"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting git+https://github.com/andreinechaev/nvcc4jupyter.git\n","  Cloning https://github.com/andreinechaev/nvcc4jupyter.git to /tmp/pip-req-build-ug8cfjdd\n","  Running command git clone --filter=blob:none --quiet https://github.com/andreinechaev/nvcc4jupyter.git /tmp/pip-req-build-ug8cfjdd\n","  Resolved https://github.com/andreinechaev/nvcc4jupyter.git to commit aac710a35f52bb78ab34d2e52517237941399eff\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Building wheels for collected packages: NVCCPlugin\n","  Building wheel for NVCCPlugin (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for NVCCPlugin: filename=NVCCPlugin-0.0.2-py3-none-any.whl size=4287 sha256=3b19e395811e797f45242f45dad6282238493659285eaa3f7aaf5c43a6fa39f6\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-s6z_wz19/wheels/a8/b9/18/23f8ef71ceb0f63297dd1903aedd067e6243a68ea756d6feea\n","Successfully built NVCCPlugin\n","Installing collected packages: NVCCPlugin\n","Successfully installed NVCCPlugin-0.0.2\n"]}]},{"cell_type":"code","source":["%load_ext nvcc_plugin"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QZT5zC4n8grM","executionInfo":{"status":"ok","timestamp":1684849210695,"user_tz":-330,"elapsed":1171,"user":{"displayName":"Neelam Khada","userId":"05506283173872221635"}},"outputId":"3510c940-b6bf-4cf2-d3a8-270365a30195"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["created output directory at /content/src\n","Out bin /content/result.out\n"]}]},{"cell_type":"code","source":["%%cu\n","#include <iostream>\n","\tint\n","\tmain()\n","{\n","\tstd::cout << \"Welcome To GeeksforGeeks\\n\";\n","\treturn 0;\n","}\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jrCTJdJI8lrg","executionInfo":{"status":"ok","timestamp":1684817474672,"user_tz":-330,"elapsed":2790,"user":{"displayName":"Neelam Khada","userId":"05506283173872221635"}},"outputId":"acb6c9b5-0491-4bc1-a34f-bc112cfe5f11"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Welcome To GeeksforGeeks\n","\n"]}]},{"cell_type":"code","source":["%%cu\n","#include<stdio.h>\n","\n","\n","__global__ void arradd(int *x,int *y, int *z)    //kernel definition\n","{\n","    int id=blockIdx.x; \n","/* blockIdx.x gives the respective block id which starts from 0 */\n","    z[id]=x[id]+y[id];\n","}\n","\n","int main()\n","{\n","    int a[6];\n","    int b[6];\n","    int c[6];\n","    int *d,*e,*f;\n","    int i;\n","    printf(\"\\n Enter six elements of first array\\n\");\n","    for(i=0;i<6;i++)\n","    {\n","        scanf(\"%d\",&a[i]);\n","    }\n","    printf(\"\\n Enter six elements of second array\\n\");\n","        for(i=0;i<6;i++)\n","        {\n","            scanf(\"%d\",&b[i]);\n","        }\n","\n","/* cudaMalloc() allocates memory from Global memory on GPU */\n","    cudaMalloc((void **)&d,6*sizeof(int));\n","    cudaMalloc((void **)&e,6*sizeof(int));\n","    cudaMalloc((void **)&f,6*sizeof(int));\n","\n","/* cudaMemcpy() copies the contents from destination to source. Here destination is GPU(d,e) and source is CPU(a,b) */\n","    cudaMemcpy(d,a,6*sizeof(int),cudaMemcpyHostToDevice);   \n","    cudaMemcpy(e,b,6*sizeof(int),cudaMemcpyHostToDevice);\n"," \n","/* call to kernel. Here 6 is number of blocks, 1 is the number of threads per block and d,e,f are the arguments */ \n","    arradd<<<6,1>>>(d,e,f); \n","\n","/* Here we are copying content from GPU(Device) to CPU(Host) */\n","    cudaMemcpy(c,f,6*sizeof(int),cudaMemcpyDeviceToHost);\n","    \n","    printf(\"\\nSum of two arrays:\\n \");\n","    for(i=0;i<6;i++)\n","    {\n","        printf(\"%d\\t\",c[i]);\n","    }\n","\n","/* Free the memory allocated to pointers d,e,f */\n","    cudaFree(d);\n","    cudaFree(e);\n","    cudaFree(f);\n","    return 0;\n","}"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RH3moKzY8tIr","executionInfo":{"status":"ok","timestamp":1684850316597,"user_tz":-330,"elapsed":1098,"user":{"displayName":"Neelam Khada","userId":"05506283173872221635"}},"outputId":"41c6c59c-51b3-4cd9-fee9-b50c1e756670"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["\n"," Enter six elements of first array\n","\n"," Enter six elements of second array\n","\n","Sum of two arrays:\n"," -2128126428\t32765\t-510143990\t43850\t-108167448\t32763\t\n"]}]},{"cell_type":"code","source":["%%cu\n","#include <stdio.h>\n","\n","#define N 10\n","\n","__global__ void vectorAdd(int *a, int *b, int *c)\n","{\n","    int tid = blockIdx.x * blockDim.x + threadIdx.x;\n","    \n","    if (tid < N)\n","        c[tid] = a[tid] + b[tid];\n","}\n","\n","int main()\n","{\n","    int a[N], b[N], c[N];\n","    int *dev_a, *dev_b, *dev_c;\n","    \n","    // Allocate memory on the device\n","    cudaMalloc((void **)&dev_a, N * sizeof(int));\n","    cudaMalloc((void **)&dev_b, N * sizeof(int));\n","    cudaMalloc((void **)&dev_c, N * sizeof(int));\n","    \n","    // Initialize input vectors\n","    for (int i = 0; i < N; i++)\n","    {\n","        a[i] = i;\n","        b[i] = i * i;\n","    }\n","    \n","    // Copy input vectors from host memory to device memory\n","    cudaMemcpy(dev_a, a, N * sizeof(int), cudaMemcpyHostToDevice);\n","    cudaMemcpy(dev_b, b, N * sizeof(int), cudaMemcpyHostToDevice);\n","    \n","    // Launch vector addition kernel on the GPU\n","    int blockSize = 256;\n","    int gridSize = (int)ceil((float)N / blockSize);\n","    vectorAdd<<<gridSize, blockSize>>>(dev_a, dev_b, dev_c);\n","    \n","    // Copy result vector from device memory to host memory\n","    cudaMemcpy(c, dev_c, N * sizeof(int), cudaMemcpyDeviceToHost);\n","    \n","    // Print the result\n","    for (int i = 0; i < N; i++)\n","    {\n","        printf(\"%d + %d = %d\\n\", a[i], b[i], c[i]);\n","    }\n","    \n","    // Free device memory\n","    cudaFree(dev_a);\n","    cudaFree(dev_b);\n","    cudaFree(dev_c);\n","    \n","    return 0;\n","}\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"isNDR0UP_Vbf","executionInfo":{"status":"ok","timestamp":1684850283170,"user_tz":-330,"elapsed":2296,"user":{"displayName":"Neelam Khada","userId":"05506283173872221635"}},"outputId":"818192c4-0406-4cd9-f133-cc545e44362f"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["0 + 0 = 0\n","1 + 1 = 2\n","2 + 4 = 6\n","3 + 9 = 12\n","4 + 16 = 20\n","5 + 25 = 30\n","6 + 36 = 42\n","7 + 49 = 56\n","8 + 64 = 72\n","9 + 81 = 90\n","\n"]}]},{"cell_type":"code","source":["%%cu\n","#include<stdio.h>\n","\n","\n","_global_ void arradd(int *x,int *y, int *z)    //kernel definition\n","{\n","  int id=blockIdx.x; \n","/* blockIdx.x gives the respective block id which starts from 0 */\n","  z[id]=x[id]+y[id];\n","}\n","\n","int main()\n","{\n","    int a[6];\n","    int b[6];\n","    int c[6];\n","    int *d,*e,*f;\n","    int i;\n","    printf(\"\\n Enter six elements of first array\\n\");\n","    for(i=0;i<6;i++)\n","    {\n","        scanf(\"%d\",&a[i]);\n","    }\n","    printf(\"\\n Enter six elements of second array\\n\");\n","        for(i=0;i<6;i++)\n","        {\n","            scanf(\"%d\",&b[i]);\n","        }\n","\n","/* cudaMalloc() allocates memory from Global memory on GPU */\n","    cudaMalloc((void **)&d,6*sizeof(int));\n","    cudaMalloc((void **)&e,6*sizeof(int));\n","    cudaMalloc((void **)&f,6*sizeof(int));\n","\n","/* cudaMemcpy() copies the contents from destination to source. Here destination is GPU(d,e) and source is CPU(a,b) */\n"," cudaMemcpy(d,a,6*sizeof(int),cudaMemcpyHostToDevice);   \n"," cudaMemcpy(e,b,6*sizeof(int),cudaMemcpyHostToDevice);\n"," \n","/* call to kernel. Here 6 is number of blocks, 1 is the number of threads per block and d,e,f are the arguments */ \n","arradd<<<6,1>>>(d,e,f); \n","\n","/* Here we are copying content from GPU(Device) to CPU(Host) */\n"," cudaMemcpy(c,f,6*sizeof(int),cudaMemcpyDeviceToHost);\n","    \n","printf(\"\\nSum of two arrays:\\n \");\n","    for(i=0;i<6;i++)\n","    {\n","        printf(\"%d\\t\",c[i]);\n","    }\n","\n","/* Free the memory allocated to pointers d,e,f */\n","    \n","    return 0;\n","}"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lxNmooIs98D7","executionInfo":{"status":"ok","timestamp":1684850405519,"user_tz":-330,"elapsed":1335,"user":{"displayName":"Neelam Khada","userId":"05506283173872221635"}},"outputId":"78dbeabc-5920-4d80-838e-b5a5a2ed1755"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["/tmp/tmpniqb9xja/edb7d2d8-b515-4ab6-a3c2-ef7403deb555.cu(4): error: this declaration has no storage class or type specifier\n","\n","/tmp/tmpniqb9xja/edb7d2d8-b515-4ab6-a3c2-ef7403deb555.cu(4): error: expected a \";\"\n","\n","/tmp/tmpniqb9xja/edb7d2d8-b515-4ab6-a3c2-ef7403deb555.cu(35): warning #12-D: parsing restarts here after previous syntax error\n","\n","/tmp/tmpniqb9xja/edb7d2d8-b515-4ab6-a3c2-ef7403deb555.cu(36): error: this declaration has no storage class or type specifier\n","\n","/tmp/tmpniqb9xja/edb7d2d8-b515-4ab6-a3c2-ef7403deb555.cu(36): error: declaration is incompatible with \"cudaError_t cudaMemcpy(void *, const void *, size_t, cudaMemcpyKind)\"\n","/usr/local/cuda/bin/../targets/x86_64-linux/include/cuda_runtime_api.h(6266): here\n","\n","/tmp/tmpniqb9xja/edb7d2d8-b515-4ab6-a3c2-ef7403deb555.cu(36): error: identifier \"e\" is undefined\n","\n","/tmp/tmpniqb9xja/edb7d2d8-b515-4ab6-a3c2-ef7403deb555.cu(36): error: identifier \"b\" is undefined\n","\n","/tmp/tmpniqb9xja/edb7d2d8-b515-4ab6-a3c2-ef7403deb555.cu(36): error: too many initializer values\n","\n","/tmp/tmpniqb9xja/edb7d2d8-b515-4ab6-a3c2-ef7403deb555.cu(39): error: this declaration has no storage class or type specifier\n","\n","/tmp/tmpniqb9xja/edb7d2d8-b515-4ab6-a3c2-ef7403deb555.cu(39): error: expected a \";\"\n","\n","/tmp/tmpniqb9xja/edb7d2d8-b515-4ab6-a3c2-ef7403deb555.cu(42): error: this declaration has no storage class or type specifier\n","\n","/tmp/tmpniqb9xja/edb7d2d8-b515-4ab6-a3c2-ef7403deb555.cu(42): error: variable \"cudaMemcpy\" has already been defined\n","\n","/tmp/tmpniqb9xja/edb7d2d8-b515-4ab6-a3c2-ef7403deb555.cu(42): error: identifier \"c\" is undefined\n","\n","/tmp/tmpniqb9xja/edb7d2d8-b515-4ab6-a3c2-ef7403deb555.cu(42): error: identifier \"f\" is undefined\n","\n","/tmp/tmpniqb9xja/edb7d2d8-b515-4ab6-a3c2-ef7403deb555.cu(42): error: too many initializer values\n","\n","/tmp/tmpniqb9xja/edb7d2d8-b515-4ab6-a3c2-ef7403deb555.cu(44): error: this declaration has no storage class or type specifier\n","\n","/tmp/tmpniqb9xja/edb7d2d8-b515-4ab6-a3c2-ef7403deb555.cu(44): error: declaration is incompatible with \"int printf(const char *, ...)\"\n","/usr/local/cuda/bin/../targets/x86_64-linux/include/crt/common_functions.h(153): here\n","\n","/tmp/tmpniqb9xja/edb7d2d8-b515-4ab6-a3c2-ef7403deb555.cu(44): error: a value of type \"const char *\" cannot be used to initialize an entity of type \"int\"\n","\n","/tmp/tmpniqb9xja/edb7d2d8-b515-4ab6-a3c2-ef7403deb555.cu(45): error: expected a declaration\n","\n","/tmp/tmpniqb9xja/edb7d2d8-b515-4ab6-a3c2-ef7403deb555.cu(52): warning #12-D: parsing restarts here after previous syntax error\n","\n","/tmp/tmpniqb9xja/edb7d2d8-b515-4ab6-a3c2-ef7403deb555.cu(53): error: expected a declaration\n","\n","19 errors detected in the compilation of \"/tmp/tmpniqb9xja/edb7d2d8-b515-4ab6-a3c2-ef7403deb555.cu\".\n","\n"]}]},{"cell_type":"code","source":["%%cu\n","#include <stdio.h>\n","\n","#define N 1\n","\n","__global__ void vectorAdd(int *a, int *b, int *c)\n","{\n","    int tid = blockIdx.x * blockDim.x + threadIdx.x;\n","    \n","    if (tid < N)\n","        c[tid] = a[tid] + b[tid];\n","}\n","\n","int main()\n","{\n","    int a[N], b[N], c[N];\n","    int *dev_a, *dev_b, *dev_c;\n","    \n","    // Allocate memory on the device\n","    cudaMalloc((void **)&dev_a, N * sizeof(int));\n","    cudaMalloc((void **)&dev_b, N * sizeof(int));\n","    cudaMalloc((void **)&dev_c, N * sizeof(int));\n","    \n","    // Initialize input vectors\n","    for (int i = 0; i < N; i++)\n","    {\n","        a[i] = 5;\n","        b[i] = 7;\n","    }\n","    \n","    // Copy input vectors from host memory to device memory\n","    cudaMemcpy(dev_a, a, N * sizeof(int), cudaMemcpyHostToDevice);\n","    cudaMemcpy(dev_b, b, N * sizeof(int), cudaMemcpyHostToDevice);\n","    \n","    // Launch vector addition kernel on the GPU\n","    int blockSize = 256;\n","    int gridSize = (int)ceil((float)N / blockSize);\n","    vectorAdd<<<gridSize, blockSize>>>(dev_a, dev_b, dev_c);\n","    \n","    // Copy result vector from device memory to host memory\n","    cudaMemcpy(c, dev_c, N * sizeof(int), cudaMemcpyDeviceToHost);\n","    \n","    // Print the result\n","    printf(\"%d + %d = %d\\n\", a[0], b[0], c[0]);\n","    \n","    // Free device memory\n","    cudaFree(dev_a);\n","    cudaFree(dev_b);\n","    cudaFree(dev_c);\n","    \n","    return 0;\n","}\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_WIXwwmbAdDY","executionInfo":{"status":"ok","timestamp":1684850432714,"user_tz":-330,"elapsed":2247,"user":{"displayName":"Neelam Khada","userId":"05506283173872221635"}},"outputId":"30d0443d-99d6-4b56-93a9-11157e223a20"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["5 + 7 = 12\n","\n"]}]},{"cell_type":"code","source":["%%cu\n","#include <stdio.h>\n","#include <stdlib.h>\n","#include <assert.h>\n","\n","#define BLOCK_SIZE 16\n","\n","\\\n","__global__ void gpu_matrix_mult(int *a,int *b, int *c, int m, int n, int k)\n","{ \n","    int row = blockIdx.y * blockDim.y + threadIdx.y; \n","    int col = blockIdx.x * blockDim.x + threadIdx.x;\n","    int sum = 0;\n","    if( col < k && row < m) \n","    {\n","        for(int i = 0; i < n; i++) \n","        {\n","            sum += a[row * n + i] * b[i * k + col];\n","        }\n","        c[row * k + col] = sum;\n","    }\n","} \n","\n","\n","\n","__global__ void gpu_square_matrix_mult(int *d_a, int *d_b, int *d_result, int n) \n","{\n","    __shared__ int tile_a[BLOCK_SIZE][BLOCK_SIZE];\n","    __shared__ int tile_b[BLOCK_SIZE][BLOCK_SIZE];\n","\n","    int row = blockIdx.y * BLOCK_SIZE + threadIdx.y;\n","    int col = blockIdx.x * BLOCK_SIZE + threadIdx.x;\n","    int tmp = 0;\n","    int idx;\n","\n","    for (int sub = 0; sub < gridDim.x; ++sub) \n","    {\n","        idx = row * n + sub * BLOCK_SIZE + threadIdx.x;\n","        if(idx >= n*n)\n","        {\n","            // n may not divisible by BLOCK_SIZE\n","            tile_a[threadIdx.y][threadIdx.x] = 0;\n","        }\n","        else\n","        {\n","            tile_a[threadIdx.y][threadIdx.x] = d_a[idx];\n","        }\n","\n","        idx = (sub * BLOCK_SIZE + threadIdx.y) * n + col;\n","        if(idx >= n*n)\n","        {\n","            tile_b[threadIdx.y][threadIdx.x] = 0;\n","        }  \n","        else\n","        {\n","            tile_b[threadIdx.y][threadIdx.x] = d_b[idx];\n","        }\n","        __syncthreads();\n","\n","        for (int k = 0; k < BLOCK_SIZE; ++k) \n","        {\n","            tmp += tile_a[threadIdx.y][k] * tile_b[k][threadIdx.x];\n","        }\n","        __syncthreads();\n","    }\n","    if(row < n && col < n)\n","    {\n","        d_result[row * n + col] = tmp;\n","    }\n","}\n","\n","\n","\n","__global__ void gpu_matrix_transpose(int* mat_in, int* mat_out, unsigned int rows, unsigned int cols) \n","{\n","    unsigned int idx = blockIdx.x * blockDim.x + threadIdx.x;\n","    unsigned int idy = blockIdx.y * blockDim.y + threadIdx.y;\n","\n","    if (idx < cols && idy < rows) \n","    {\n","        unsigned int pos = idy * cols + idx;\n","        unsigned int trans_pos = idx * rows + idy;\n","        mat_out[trans_pos] = mat_in[pos];\n","    }\n","}\n","\n","void cpu_matrix_mult(int *h_a, int *h_b, int *h_result, int m, int n, int k) {\n","    for (int i = 0; i < m; ++i) \n","    {\n","        for (int j = 0; j < k; ++j) \n","        {\n","            int tmp = 0.0;\n","            for (int h = 0; h < n; ++h) \n","            {\n","                tmp += h_a[i * n + h] * h_b[h * k + j];\n","            }\n","            h_result[i * k + j] = tmp;\n","        }\n","    }\n","}\n","\n","\n","int main(int argc, char const *argv[])\n","{\n","    int m, n, k;\n","    /* Fixed seed for illustration */\n","    srand(3333);\n","    printf(\"please type in m n and k\\n\");\n","    scanf(\"%d %d %d\", &m, &n, &k);\n","\n","    // allocate memory in host RAM, h_cc is used to store CPU result\n","    int *h_a, *h_b, *h_c, *h_cc;\n","    cudaMallocHost((void **) &h_a, sizeof(int)*m*n);\n","    cudaMallocHost((void **) &h_b, sizeof(int)*n*k);\n","    cudaMallocHost((void **) &h_c, sizeof(int)*m*k);\n","    cudaMallocHost((void **) &h_cc, sizeof(int)*m*k);\n","\n","    // random initialize matrix A\n","    for (int i = 0; i < m; ++i) {\n","        for (int j = 0; j < n; ++j) {\n","            h_a[i * n + j] = rand() % 1024;\n","        }\n","    }\n","\n","    // random initialize matrix B\n","    for (int i = 0; i < n; ++i) {\n","        for (int j = 0; j < k; ++j) {\n","            h_b[i * k + j] = rand() % 1024;\n","        }\n","    }\n","\n","    float gpu_elapsed_time_ms, cpu_elapsed_time_ms;\n","\n","    // some events to count the execution time\n","    cudaEvent_t start, stop;\n","    cudaEventCreate(&start);\n","    cudaEventCreate(&stop);\n","\n","    // start to count execution time of GPU version\n","    cudaEventRecord(start, 0);\n","    // Allocate memory space on the device \n","    int *d_a, *d_b, *d_c;\n","    cudaMalloc((void **) &d_a, sizeof(int)*m*n);\n","    cudaMalloc((void **) &d_b, sizeof(int)*n*k);\n","    cudaMalloc((void **) &d_c, sizeof(int)*m*k);\n","\n","    // copy matrix A and B from host to device memory\n","    cudaMemcpy(d_a, h_a, sizeof(int)*m*n, cudaMemcpyHostToDevice);\n","    cudaMemcpy(d_b, h_b, sizeof(int)*n*k, cudaMemcpyHostToDevice);\n","\n","    unsigned int grid_rows = (m + BLOCK_SIZE - 1) / BLOCK_SIZE;\n","    unsigned int grid_cols = (k + BLOCK_SIZE - 1) / BLOCK_SIZE;\n","    dim3 dimGrid(grid_cols, grid_rows);\n","    dim3 dimBlock(BLOCK_SIZE, BLOCK_SIZE);\n","   \n","    // Launch kernel \n","    if(m == n && n == k)\n","    {\n","        gpu_square_matrix_mult<<<dimGrid, dimBlock>>>(d_a, d_b, d_c, n);    \n","    }\n","    else\n","    {\n","        gpu_matrix_mult<<<dimGrid, dimBlock>>>(d_a, d_b, d_c, m, n, k);    \n","    }\n","    // Transefr results from device to host \n","    cudaMemcpy(h_c, d_c, sizeof(int)*m*k, cudaMemcpyDeviceToHost);\n","    cudaThreadSynchronize();\n","    // time counting terminate\n","    cudaEventRecord(stop, 0);\n","    cudaEventSynchronize(stop);\n","\n","    // compute time elapse on GPU computing\n","    cudaEventElapsedTime(&gpu_elapsed_time_ms, start, stop);\n","    printf(\"Time elapsed on matrix multiplication of %dx%d . %dx%d on GPU: %f ms.\\n\\n\", m, n, n, k, gpu_elapsed_time_ms);\n","\n","    // start the CPU version\n","    cudaEventRecord(start, 0);\n","\n","    cpu_matrix_mult(h_a, h_b, h_cc, m, n, k);\n","\n","    cudaEventRecord(stop, 0);\n","    cudaEventSynchronize(stop);\n","    cudaEventElapsedTime(&cpu_elapsed_time_ms, start, stop);\n","    printf(\"Time elapsed on matrix multiplication of %dx%d . %dx%d on CPU: %f ms.\\n\\n\", m, n, n, k, cpu_elapsed_time_ms);\n","\n","    // validate results computed by GPU\n","    int all_ok = 1;\n","    for (int i = 0; i < m; ++i)\n","    {\n","        for (int j = 0; j < k; ++j)\n","        {\n","            //printf(\"[%d][%d]:%d == [%d][%d]:%d, \", i, j, h_cc[i*k + j], i, j, h_c[i*k + j]);\n","            if(h_cc[i*k + j] != h_c[i*k + j])\n","            {\n","                all_ok = 0;\n","            }\n","        }\n","        //printf(\"\\n\");\n","    }\n","\n","    // roughly compute speedup\n","    if(all_ok)\n","    {\n","        printf(\"all results are correct!!!, speedup = %f\\n\", cpu_elapsed_time_ms / gpu_elapsed_time_ms);\n","    }\n","    else\n","    {\n","        printf(\"incorrect results\\n\");\n","    }\n","\n","    // free memory\n","    cudaFree(d_a);\n","    cudaFree(d_b);\n","    cudaFree(d_c);\n","    cudaFreeHost(h_a);\n","    cudaFreeHost(h_b);\n","    cudaFreeHost(h_c);\n","    cudaFreeHost(h_cc);\n","    return 0;\n","}"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wCdBqDLdChdX","executionInfo":{"status":"ok","timestamp":1684850535771,"user_tz":-330,"elapsed":2229,"user":{"displayName":"Neelam Khada","userId":"05506283173872221635"}},"outputId":"90a9df83-4c1a-4ba9-b213-f023920af421"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["please type in m n and k\n","Time elapsed on matrix multiplication of -672198864x21948 . 21948x-705574946 on GPU: 0.026880 ms.\n","\n","Time elapsed on matrix multiplication of -672198864x21948 . 21948x-705574946 on CPU: 0.002336 ms.\n","\n","all results are correct!!!, speedup = 0.086905\n","\n"]}]},{"cell_type":"code","source":["%%cu\n","#include <iostream>\n","using namespace std;\n","\n","\n","// CUDA code to multiply matrices\n","__global__ void multiply(int* A, int* B, int* C, int size) {\n","    // Uses thread indices and block indices to compute each element\n","    int row = blockIdx.y * blockDim.y + threadIdx.y;\n","    int col = blockIdx.x * blockDim.x + threadIdx.x;\n","\n","    if (row < size && col < size) {\n","        int sum = 0;\n","        for (int i = 0; i < size; i++) {\n","            sum += A[row * size + i] * B[i * size + col];\n","        }\n","        C[row * size + col] = sum;\n","    }\n","}\n","\n","\n","void initialize(int* matrix, int size) {\n","    for (int i = 0; i < size * size; i++) {\n","        matrix[i] = rand() % 10;\n","    }\n","}\n","\n","\n","void print(int* matrix, int size) {\n","    for (int row = 0; row < size; row++) {\n","        for (int col = 0; col < size; col++) {\n","            cout << matrix[row * size + col] << \" \";\n","        }\n","        cout << '\\n';\n","    }\n","    cout << '\\n';\n","}\n","\n","\n","int main() {\n","    int* A, * B, * C;\n","\n","    int N = 2;\n","    int blockSize =  16;\n","\n","    int matrixSize = N * N;\n","    size_t matrixBytes = matrixSize * sizeof(int);\n","\n","    A = new int[matrixSize];\n","    B = new int[matrixSize];\n","    C = new int[matrixSize];\n","\n","    initialize(A, N);\n","    initialize(B, N);\n","    cout << \"Matrix A: \\n\";\n","    print(A, N);\n","\n","    cout << \"Matrix B: \\n\";\n","    print(B, N);\n","\n","    \n","    int* X, * Y, * Z;\n","    // Allocate space\n","    cudaMalloc(&X, matrixBytes);\n","    cudaMalloc(&Y, matrixBytes);\n","    cudaMalloc(&Z, matrixBytes);\n","\n","    // Copy values from A to X\n","    cudaMemcpy(X, A, matrixBytes, cudaMemcpyHostToDevice);\n","    \n","    // Copy values from A to X and B to Y\n","    cudaMemcpy(Y, B, matrixBytes, cudaMemcpyHostToDevice);\n","\n","    // Threads per CTA dimension\n","    int THREADS = 2;\n","\n","    // Blocks per grid dimension (assumes THREADS divides N evenly)\n","    int BLOCKS = N / THREADS;\n","\n","    // Use dim3 structs for block  and grid dimensions\n","    dim3 threads(THREADS, THREADS);\n","    dim3 blocks(BLOCKS, BLOCKS);\n","\n","    // Launch kernel\n","    multiply<<<blocks, threads>>>(X, Y, Z, N);\n","\n","    cudaMemcpy(C, Z, matrixBytes, cudaMemcpyDeviceToHost);\n","    cout << \"Multiplication of matrix A and B: \\n\";\n","    print(C, N);\n","\n","    delete[] A;\n","    delete[] B;\n","    delete[] C;\n","\n","    cudaFree(X);\n","    cudaFree(Y);\n","    cudaFree(Z);\n","\n","    return 0;\n","}"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5RTPkGhD1I1r","executionInfo":{"status":"ok","timestamp":1684849264738,"user_tz":-330,"elapsed":3733,"user":{"displayName":"Neelam Khada","userId":"05506283173872221635"}},"outputId":"b41cddab-9a25-4966-f14a-bf0e8b49b180"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Matrix A: \n","3 6 \n","7 5 \n","\n","Matrix B: \n","3 5 \n","6 2 \n","\n","Multiplication of matrix A and B: \n","45 27 \n","51 45 \n","\n","\n"]}]},{"cell_type":"code","source":["%%cu\n","#include <iostream>\n","using namespace std;\n","\n","__global__ void add(int* A, int* B, int* C, int size) {\n","    int tid = blockIdx.x * blockDim.x + threadIdx.x;\n","\n","    if (tid < size) {\n","        C[tid] = A[tid] + B[tid];\n","    }\n","}\n","\n","\n","void initialize(int* vector, int size) {\n","    for (int i = 0; i < size; i++) {\n","        vector[i] = rand() % 10;\n","    }\n","}\n","\n","void print(int* vector, int size) {\n","    for (int i = 0; i < size; i++) {\n","        cout << vector[i] << \" \";\n","    }\n","    cout << endl;\n","}\n","\n","int main() {\n","    int N = 4;\n","    int* A, * B, * C;\n","\n","    int vectorSize = N;\n","    size_t vectorBytes = vectorSize * sizeof(int);\n","\n","    A = new int[vectorSize];\n","    B = new int[vectorSize];\n","    C = new int[vectorSize];\n","\n","    initialize(A, vectorSize);\n","    initialize(B, vectorSize);\n","\n","    cout << \"Vector A: \";\n","    print(A, N);\n","    cout << \"Vector B: \";\n","    print(B, N);\n","\n","    int* X, * Y, * Z;\n","    cudaMalloc(&X, vectorBytes);\n","    cudaMalloc(&Y, vectorBytes);\n","    cudaMalloc(&Z, vectorBytes);\n","\n","    cudaMemcpy(X, A, vectorBytes, cudaMemcpyHostToDevice);\n","    cudaMemcpy(Y, B, vectorBytes, cudaMemcpyHostToDevice);\n","\n","    int threadsPerBlock = 256;\n","    int blocksPerGrid = (N + threadsPerBlock - 1) / threadsPerBlock;\n","\n","    add<<<blocksPerGrid, threadsPerBlock>>>(X, Y, Z, N);\n","\n","    cudaMemcpy(C, Z, vectorBytes, cudaMemcpyDeviceToHost);\n","\n","    cout << \"Addition: \";\n","    print(C, N);\n","\n","    delete[] A;\n","    delete[] B;\n","    delete[] C;\n","\n","    cudaFree(X);\n","    cudaFree(Y);\n","    cudaFree(Z);\n","\n","    return 0;\n","}\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pFwrStSv2--T","executionInfo":{"status":"ok","timestamp":1684849583058,"user_tz":-330,"elapsed":1858,"user":{"displayName":"Neelam Khada","userId":"05506283173872221635"}},"outputId":"ead2f6f4-6be6-4c1b-8088-707943fa62d8"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Vector A: 3 6 7 5 \n","Vector B: 3 5 6 2 \n","Addition: 6 11 13 7 \n","\n"]}]}]}